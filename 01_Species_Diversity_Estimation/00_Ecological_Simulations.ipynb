{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lAs4Oq4JmkZ8"
      },
      "outputs": [],
      "source": [
        "###############################################################\n",
        "\n",
        "# KDE-entropy (bits) on PC1 / PC1–PC2 / PC1–PC2–PC3\n",
        "# vs Shannon diversity (bits) from species counts.\n",
        "# Bandwidth sensitivity: h = α·h*, α ∈ {1/2, 1/√2, 1, √2}\n",
        "#\n",
        "# Plot simulation results\n",
        "\n",
        "###############################################################\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import defaultdict\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from scipy.stats import pearsonr, t\n",
        "from matplotlib.ticker import MaxNLocator, AutoMinorLocator\n",
        "\n",
        "# Model parameters\n",
        "RNG_SEED       = None\n",
        "N_COMM_TRAIN   = 100\n",
        "N_GRAINS       = 50\n",
        "MIN_SPECIES    = 1\n",
        "MAX_SPECIES    = 30\n",
        "MAX_PC_FOR_PCA = 3\n",
        "HSTAR_GRID_KW  = dict(h_min=1e-2, h_max=1e1, num=400, logspace=True)\n",
        "\n",
        "OUTPUT_PDF_SENS = \"kde_entropy_vs_shannon_h_sensitivity_with_CI_PI_lines.pdf\"\n",
        "H_SCALES        = [0.5, 2**(-0.5), 1.0, 2**0.5]\n",
        "\n",
        "# For figure\n",
        "ALPHA_X = -0.15\n",
        "ALPHA_FONTSIZE = 13\n",
        "YLABEL_PAD = 36\n",
        "POINT_SIZE = 18\n",
        "LINE_WIDTH = 2.0\n",
        "LABEL_FONTSIZE = 14\n",
        "STATS_FONTSIZE = 10\n",
        "\n",
        "COLOR_POINTS = \"#6b7280\"\n",
        "COLOR_LINE   = \"#111827\"\n",
        "COLOR_CI     = \"#6b7280\"\n",
        "COLOR_PI     = \"#9ca3af\"\n",
        "GRID_COLOR   = \"#d1d5db\"\n",
        "\n",
        "# Helpers\n",
        "def to_numpy_array(X):\n",
        "    if hasattr(X, \"detach\"): return X.detach().cpu().numpy()\n",
        "    if hasattr(X, \"to_numpy\"): return X.to_numpy()\n",
        "    return np.asarray(X)\n",
        "\n",
        "def build_species_index(labels):\n",
        "    d = defaultdict(list)\n",
        "    for i, sp in enumerate(labels):\n",
        "        d[int(sp)].append(i)\n",
        "    return {k: np.asarray(v, dtype=int) for k, v in d.items()}\n",
        "\n",
        "# Simulating different communities\n",
        "def sample_community_indices(species_index, N, rng, min_species, max_species):\n",
        "    species_list = list(species_index.keys())\n",
        "    minS = max(1, min_species)\n",
        "    maxS = min(max_species, len(species_list))\n",
        "    if minS > maxS:\n",
        "        raise ValueError(\"min_species > max_species given available species.\")\n",
        "\n",
        "    for _ in range(2000):\n",
        "        S = int(rng.integers(minS, maxS + 1))\n",
        "        picks = rng.choice(species_list, size=S, replace=False)\n",
        "\n",
        "        tau = float(np.exp(rng.uniform(np.log(0.01), np.log(20.0))))\n",
        "        alpha = np.full(S, tau / S, dtype=float)\n",
        "        p = rng.dirichlet(alpha)\n",
        "        counts = rng.multinomial(N, p).astype(int)\n",
        "\n",
        "        if counts.sum() != N:\n",
        "            diff = N - counts.sum()\n",
        "            j = int(rng.integers(0, S))\n",
        "            counts[j] = max(0, counts[j] + diff)\n",
        "\n",
        "        avail = np.array([len(species_index[s]) for s in picks], dtype=int)\n",
        "        for _inner in range(5):\n",
        "            over = counts - avail\n",
        "            if np.all(over <= 0): break\n",
        "            excess = int(over[over > 0].sum())\n",
        "            counts = np.minimum(counts, avail)\n",
        "            cap = np.maximum(avail - counts, 0)\n",
        "            if cap.sum() == 0: break\n",
        "            w = cap / cap.sum()\n",
        "            add = np.floor(excess * w).astype(int)\n",
        "            rem = excess - add.sum()\n",
        "            if rem > 0:\n",
        "                idxs = rng.choice(np.arange(S), size=rem, replace=True, p=w)\n",
        "                add[idxs] += 1\n",
        "            counts += add\n",
        "\n",
        "        if np.any(counts > avail) or counts.sum() != N: continue\n",
        "\n",
        "        chosen = []\n",
        "        for s, cnt in zip(picks, counts):\n",
        "            if cnt > 0:\n",
        "                chosen.extend(rng.choice(species_index[s], size=cnt, replace=False))\n",
        "        chosen = np.asarray(chosen, dtype=int)\n",
        "        if len(chosen) == N: return chosen\n",
        "\n",
        "    raise RuntimeError(\"Could not sample valid community (availability too tight?).\")\n",
        "\n",
        "def shannon_diversity_bits_from_counts(counts):\n",
        "    n = counts.sum()\n",
        "    if n <= 0: return np.nan\n",
        "    p = counts[counts > 0] / n\n",
        "    return float(-(p * (np.log(p)/np.log(2.0))).sum())\n",
        "\n",
        "# Estimating entropy from KDE in PC space\n",
        "def _pairwise_sq_dists(X):\n",
        "    X = np.asarray(X, float)\n",
        "    norms = np.sum(X * X, axis=1, keepdims=True)\n",
        "    return norms + norms.T - 2.0 * (X @ X.T)\n",
        "\n",
        "def loo_mean_loglik_gaussian_iso(X, h):\n",
        "    X = np.asarray(X, float)\n",
        "    if X.ndim != 2 or X.shape[0] <= 1 or h <= 0 or not np.isfinite(h):\n",
        "        return -np.inf\n",
        "    n, d = X.shape\n",
        "    D2 = _pairwise_sq_dists(X)\n",
        "    A  = -D2 / (2.0 * h * h)\n",
        "    np.fill_diagonal(A, -np.inf)\n",
        "    row_max = np.max(A, axis=1, keepdims=True)\n",
        "    lse = row_max[:, 0] + np.log(np.sum(np.exp(A - row_max), axis=1))\n",
        "    log_const = -np.log(n - 1) - d*np.log(h) - 0.5*d*np.log(2*np.pi)\n",
        "    return float(np.mean(log_const + lse))\n",
        "\n",
        "def find_h_star_lcv(X, h_min=1e-2, h_max=1e1, num=400, logspace=True):\n",
        "    hs = (np.logspace(np.log10(h_min), np.log10(h_max), num=num)\n",
        "          if logspace else np.linspace(h_min, h_max, num=num))\n",
        "    best_h, best_val = None, -np.inf\n",
        "    for h in hs:\n",
        "        val = loo_mean_loglik_gaussian_iso(X, h)\n",
        "        if val > best_val:\n",
        "            best_val, best_h = val, h\n",
        "    return float(best_h)\n",
        "\n",
        "def kde_entropy_loo_bits(X, h):\n",
        "    X = np.asarray(X, float)\n",
        "    n, d = X.shape\n",
        "    if n <= 1 or not (np.isfinite(h) and h > 0): return np.nan\n",
        "    D2 = _pairwise_sq_dists(X)\n",
        "    A = -D2 / (2.0 * h * h)\n",
        "    np.fill_diagonal(A, -np.inf)\n",
        "    row_max = np.max(A, axis=1, keepdims=True)\n",
        "    lse = row_max[:, 0] + np.log(np.sum(np.exp(A - row_max), axis=1))\n",
        "    log_const = -np.log(n - 1) - d*np.log(h) - 0.5*d*np.log(2*np.pi)\n",
        "    log_p_hat_nats = log_const + lse\n",
        "    return float(-np.mean(log_p_hat_nats) / np.log(2.0))\n",
        "\n",
        "# Running the simulation on modern specimens\n",
        "def simulate_communities_on_modern(X_train, Y):\n",
        "    X_modern = to_numpy_array(X_train)\n",
        "    Y_modern = np.asarray(Y, int)\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "    X_scaled = scaler.fit_transform(X_modern)\n",
        "\n",
        "    n_pcs = min(MAX_PC_FOR_PCA, X_scaled.shape[1], X_scaled.shape[0] - 1)\n",
        "    pca = PCA(n_components=n_pcs, random_state=RNG_SEED)\n",
        "    Z = pca.fit_transform(X_scaled)\n",
        "\n",
        "    sp_index = build_species_index(Y_modern)\n",
        "    rng = np.random.default_rng(RNG_SEED)\n",
        "\n",
        "    comm_indices, shannon_div_bits = [], []\n",
        "    for _ in range(N_COMM_TRAIN):\n",
        "        idx = sample_community_indices(sp_index, N_GRAINS, rng, MIN_SPECIES, MAX_SPECIES)\n",
        "        labels = Y_modern[idx]\n",
        "        _, counts = np.unique(labels, return_counts=True)\n",
        "        comm_indices.append(idx)\n",
        "        shannon_div_bits.append(shannon_diversity_bits_from_counts(counts))\n",
        "\n",
        "    return Z, comm_indices, np.asarray(shannon_div_bits, float), Y_modern\n",
        "\n",
        "def compute_kde_entropy_bits_per_comm_multi_h(Z, comm_indices, h_star_by_dim, scales):\n",
        "    rows = []\n",
        "    for cid, idx in enumerate(comm_indices):\n",
        "        pts_all = Z[idx, :]\n",
        "        for d in (1, 2, 3):\n",
        "            if d > Z.shape[1]: continue\n",
        "            pts = pts_all[:, :d]\n",
        "            if pts.shape[0] <= d: continue\n",
        "            h_star = h_star_by_dim.get(d, np.nan)\n",
        "            if not (np.isfinite(h_star) and h_star > 0): continue\n",
        "            for alpha in scales:\n",
        "                h = alpha * h_star\n",
        "                if not (np.isfinite(h) and h > 0): continue\n",
        "                H_bits = kde_entropy_loo_bits(pts, h=h)\n",
        "                rows.append(dict(community_id=cid, dim=d, scale=float(alpha), H_bits=H_bits))\n",
        "    return pd.DataFrame(rows)\n",
        "\n",
        "# Plotting\n",
        "def _polish_axes(ax):\n",
        "    ax.spines['top'].set_visible(False)\n",
        "    ax.spines['right'].set_visible(False)\n",
        "    ax.xaxis.set_major_locator(MaxNLocator(nbins=5))\n",
        "    ax.yaxis.set_major_locator(MaxNLocator(nbins=5))\n",
        "    ax.xaxis.set_minor_locator(AutoMinorLocator(2))\n",
        "    ax.yaxis.set_minor_locator(AutoMinorLocator(2))\n",
        "    ax.tick_params(axis='both', which='major',\n",
        "                   length=6, width=1.0, direction='in', labelsize=12)\n",
        "    ax.tick_params(axis='both', which='minor',\n",
        "                   length=3, width=0.8, direction='in')\n",
        "\n",
        "def _alpha_math_label_inline(alpha: float) -> str:\n",
        "    if np.isclose(alpha, 0.5):         return r'$1/2$'\n",
        "    if np.isclose(alpha, 2**(-0.5)):   return r'$1/\\sqrt{2}$'\n",
        "    if np.isclose(alpha, 1.0):         return r'$1$'\n",
        "    if np.isclose(alpha, 2**0.5):      return r'$\\sqrt{2}$'\n",
        "    return rf'${alpha:.3g}$'\n",
        "\n",
        "def _format_p(p):\n",
        "    return \"p < 0.0001\" if p < 1e-4 else f\"p = {p:.3f}\"\n",
        "\n",
        "def _ols_ci_pi(x, y, xs, conf=0.95):\n",
        "    n = x.size\n",
        "    xbar = x.mean()\n",
        "    ybar = y.mean()\n",
        "    Sxx = np.sum((x - xbar)**2)\n",
        "    Sxy = np.sum((x - xbar)*(y - ybar))\n",
        "    a = Sxy / Sxx\n",
        "    b = ybar - a * xbar\n",
        "    yhat_x = a * x + b\n",
        "    resid = y - yhat_x\n",
        "    s2 = np.sum(resid**2) / (n - 2)\n",
        "    s = np.sqrt(s2)\n",
        "    yhat = a * xs + b\n",
        "\n",
        "    alpha = 1.0 - conf\n",
        "    tcrit = t.ppf(1 - alpha/2, df=n-2)\n",
        "\n",
        "    se_mean = s * np.sqrt(1/n + (xs - xbar)**2 / Sxx)\n",
        "    ci_lo = yhat - tcrit * se_mean\n",
        "    ci_hi = yhat + tcrit * se_mean\n",
        "\n",
        "    se_pred = s * np.sqrt(1 + 1/n + (xs - xbar)**2 / Sxx)\n",
        "    pi_lo = yhat - tcrit * se_pred\n",
        "    pi_hi = yhat + tcrit * se_pred\n",
        "\n",
        "    return a, b, yhat, ci_lo, ci_hi, pi_lo, pi_hi\n",
        "\n",
        "def plot_sensitivity_grid(df_H, shannon_div_bits, scales, output_pdf=None):\n",
        "    n_rows, n_cols = len(scales), 3\n",
        "    fig, axes = plt.subplots(\n",
        "        n_rows, n_cols,\n",
        "        figsize=(16, 4.35 * n_rows),\n",
        "        dpi=180,\n",
        "        sharey=True,\n",
        "        gridspec_kw={\"wspace\": 0.13, \"hspace\": 0.22}\n",
        "    )\n",
        "    if n_rows == 1:\n",
        "        axes = np.array([axes])\n",
        "\n",
        "    name_dim = {\n",
        "        1: \"KDE entropy (PC1) [bits]\",\n",
        "        2: \"KDE entropy (PC1–PC2) [bits]\",\n",
        "        3: \"KDE entropy (PC1–PC2–PC3) [bits]\",\n",
        "    }\n",
        "    dim_list = (1, 2, 3)\n",
        "\n",
        "    for r, alpha in enumerate(scales):\n",
        "        alpha_lbl = _alpha_math_label_inline(alpha)\n",
        "        for c, d in enumerate(dim_list):\n",
        "            ax = axes[r, c]\n",
        "            subd = df_H[(df_H[\"dim\"] == d) & (df_H[\"scale\"] == alpha)]\n",
        "            if subd.empty:\n",
        "                ax.axis(\"off\"); continue\n",
        "\n",
        "            x = subd[\"H_bits\"].values.astype(float)\n",
        "            y = shannon_div_bits[subd[\"community_id\"].values.astype(int)].astype(float)\n",
        "            mask = np.isfinite(x) & np.isfinite(y)\n",
        "            x, y = x[mask], y[mask]\n",
        "\n",
        "            ax.scatter(x, y, s=POINT_SIZE, alpha=0.6, color=COLOR_POINTS)\n",
        "\n",
        "            if x.size >= 3:\n",
        "                xs = np.linspace(np.nanmin(x), np.nanmax(x), 200)\n",
        "                a, b, yhat, ci_lo, ci_hi, pi_lo, pi_hi = _ols_ci_pi(x, y, xs, conf=0.95)\n",
        "\n",
        "                ax.plot(xs, pi_lo, color=COLOR_PI, lw=1.6, ls=\"--\")\n",
        "                ax.plot(xs, pi_hi, color=COLOR_PI, lw=1.6, ls=\"--\")\n",
        "                ax.plot(xs, ci_lo, color=COLOR_CI, lw=1.6, ls=\"-\")\n",
        "                ax.plot(xs, ci_hi, color=COLOR_CI, lw=1.6, ls=\"-\")\n",
        "                ax.plot(xs, yhat, lw=LINE_WIDTH, color=COLOR_LINE)\n",
        "\n",
        "                r_p, p_p = pearsonr(x, y)\n",
        "                ax.text(0.02, 0.98,\n",
        "                        f\"r = {r_p:.2f}, {_format_p(p_p)}\",\n",
        "                        transform=ax.transAxes, va=\"top\", ha=\"left\",\n",
        "                        fontsize=STATS_FONTSIZE, color=COLOR_LINE)\n",
        "\n",
        "            if r == n_rows - 1:\n",
        "                ax.set_xlabel(name_dim[d], fontsize=LABEL_FONTSIZE, labelpad=12)\n",
        "            else:\n",
        "                ax.set_xlabel(\"\")\n",
        "\n",
        "            if c == 0:\n",
        "                ax.set_ylabel(\"Shannon diversity (bits)\", fontsize=LABEL_FONTSIZE, labelpad=YLABEL_PAD)\n",
        "                ax.text(ALPHA_X, 0.5, r\"$\\alpha$ = \" + alpha_lbl,\n",
        "                        transform=ax.transAxes, rotation=90,\n",
        "                        va='center', ha='center', fontsize=ALPHA_FONTSIZE, color=COLOR_LINE,\n",
        "                        clip_on=False)\n",
        "            else:\n",
        "                ax.set_ylabel(\"\")\n",
        "\n",
        "            _polish_axes(ax)\n",
        "            ax.grid(True, alpha=0.45, which='major', color=GRID_COLOR)\n",
        "            ax.grid(True, alpha=0.25, which='minor', color=GRID_COLOR)\n",
        "\n",
        "    fig.subplots_adjust(bottom=0.08, left=0.12, right=0.985, top=0.985)\n",
        "\n",
        "    if output_pdf:\n",
        "        fig.savefig(output_pdf, format=\"pdf\", bbox_inches=\"tight\")\n",
        "        print(f\"\\nSaved sensitivity grid to: {output_pdf}\")\n",
        "    plt.show()\n",
        "    return fig\n",
        "\n",
        "# Run\n",
        "# X_train: feature matrix (n_samples × n_features), CNN embeddings (e.g., from MIP images, patches, or both)\n",
        "# Y: integer species labels per sample (length = n_samples)\n",
        "\n",
        "print(\"Starting simulation (KDE-entropy sensitivity grid with CI/PI boundaries) ...\")\n",
        "print(f\"Modern data shape: {X_train.shape}; unique species: {len(np.unique(Y))}\")\n",
        "\n",
        "Z_all, comm_indices, shannon_div_bits, Y_all = simulate_communities_on_modern(X_train, Y)\n",
        "\n",
        "# Optimal h* per dimension obtained via leave-one-out cross-validation\n",
        "h_star_by_dim = {}\n",
        "for d in (1, 2, 3):\n",
        "    if d > Z_all.shape[1]: continue\n",
        "    Zd = Z_all[:, :d]\n",
        "    h_star_by_dim[d] = find_h_star_lcv(Zd, **HSTAR_GRID_KW)\n",
        "    print(f\"h* for PC{'1' if d==1 else '1–2' if d==2 else '1–3'}: {h_star_by_dim[d]:.4g}\")\n",
        "\n",
        "df_H_sens = compute_kde_entropy_bits_per_comm_multi_h(Z_all, comm_indices, h_star_by_dim, H_SCALES)\n",
        "plot_sensitivity_grid(df_H_sens, shannon_div_bits, H_SCALES, output_pdf=OUTPUT_PDF_SENS)\n",
        "\n",
        "print(\"\\nDone.\")"
      ]
    }
  ]
}
